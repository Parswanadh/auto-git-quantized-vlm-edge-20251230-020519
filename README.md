# Quantized VLM for Edge Devices

4-bit quantized Vision-Language Model optimized for edge deployment.

## Features
- 4-bit quantization for memory efficiency
- Works on 4GB VRAM
- Vision + Language understanding

Generated by Auto-GIT: 2025-12-30 02:05:19
